"""
Pre-filter –º–æ–¥—É–ª—å: –æ—Ç—Å–µ–∏–≤–∞–µ—Ç –º—É—Å–æ—Ä–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–æ –≤—ã–∑–æ–≤–∞ AI.

–ú–Ω–æ–≥–æ—Å—Ç—É–ø–µ–Ω—á–∞—Ç–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è:
  1. Blacklist ‚Äî —Å–ª–æ–≤–∞-–º–∞—Ä–∫–µ—Ä—ã —Å–ø–∞–º–∞/—Ä–µ–∫–ª–∞–º—ã
  2. –î–ª–∏–Ω–∞ ‚Äî —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
  3. Whitelist boost ‚Äî –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–≤–µ–Ω—Ç–æ–≤
  4. –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–∞—Ç/–≤—Ä–µ–º–µ–Ω–∏
  5. –ü–∞—Ç—Ç–µ—Ä–Ω—ã –º–µ—Å—Ç
  6. –ù–∞–ª–∏—á–∏–µ –º–µ–¥–∏–∞ (—Ñ–æ—Ç–æ-—Ñ–ª–∞–µ—Ä)
"""

import re
from dataclasses import dataclass


@dataclass
class FilterResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è."""
    passed: bool
    score: int
    reason: str


# ‚îÄ‚îÄ‚îÄ Blacklist: —Å–ø–∞–º, —Ä–µ–∫–ª–∞–º–∞, —É—Å–ª—É–≥–∏ ‚îÄ‚îÄ‚îÄ

BLACKLIST_WORDS = [
    # –ù–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å
    "—Å–¥–∞–º", "—Å–Ω–∏–º—É", "–∞—Ä–µ–Ω–¥–∞", "–≤–∏–ª–ª–∞", "–∫–æ–Ω–¥–æ", "–∫–≤–∞—Ä—Ç–∏—Ä", "–∫–æ–º–Ω–∞—Ç",
    "–∂–∏–ª—å—ë", "–∂–∏–ª—å–µ", "–∞–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç", "—Ä–µ–∑–∏–¥–µ–Ω—Å", "–¥–æ–ª–≥–æ—Å—Ä–æ–∫", "–∫—Ä–∞—Ç–∫–æ—Å—Ä–æ–∫",
    # –í–∏–∑—ã –∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã
    "visa", "–≤–∏–∑–∞", "—Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–∞ —Ä–∞–±–æ—Ç—É", "work permit", "extension",
    # –ö—Ä–∏–ø—Ç–∞ –∏ –æ–±–º–µ–Ω
    "usdt", "–∫—Ä–∏–ø—Ç", "–±–∏—Ç–∫–æ–∏–Ω", "btc", "eth", "–æ–±–º–µ–Ω", "–º–µ–Ω—è—é", "–∫—É—Ä—Å –≤–∞–ª—é—Ç",
    "exchange rate", "p2p",
    # –¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç
    "–±–∞–π–∫", "nmax", "—Å–∫—É—Ç–µ—Ä", "–º–æ—Ç–æ–±–∞–π–∫", "–∞—Ä–µ–Ω–¥–∞ –±–∞–π–∫", "rent bike",
    # –£—Å–ª—É–≥–∏
    "–Ω–æ–≥–æ—Ç–æ—á–∫–∏", "–º–∞—Å—Å–∞–∂", "–º–∞–Ω–∏–∫—é—Ä", "–ø–µ–¥–∏–∫—é—Ä", "–Ω–∞—Ä–∞—â–∏–≤–∞–Ω–∏–µ", "—ç–ø–∏–ª—è—Ü–∏",
    "—Ç—Ä–∞–Ω—Å—Ñ–µ—Ä", "—Ç–∞–∫—Å–∏", "–¥–æ—Å—Ç–∞–≤–∫–∞", "–∫–ª–∏–Ω–∏–Ω–≥", "—Å—Ç–∏—Ä–∫–∞", "—É–±–æ—Ä–∫–∞",
    "—Ä–µ–º–æ–Ω—Ç", "—Å–∞–Ω—Ç–µ—Ö–Ω–∏–∫", "—ç–ª–µ–∫—Ç—Ä–∏–∫",
    # –ö–æ—Å–º–µ—Ç–æ–ª–æ–≥–∏—è
    "—Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü", "–ª–∏—Ñ—Ç–∏–Ω–≥", "—Ñ–æ—Ç–æ—Å–µ—Å—Å", "bbl", "–±–æ—Ç–æ–∫—Å", "—Ñ–∏–ª–ª–µ—Ä",
    # –ü—Ä–æ–¥–∞–∂–∞
    "–ø—Ä–æ–¥–∞–º", "–∫—É–ø–ª—é", "–ø—Ä–æ–¥–∞—é", "–±/—É", "—Ç–æ—Ä–≥",
    # –†–∞–±–æ—Ç–∞
    "–∏—â—É —Ä–∞–±–æ—Ç—É", "–≤–∞–∫–∞–Ω—Å–∏—è", "—Ç—Ä–µ–±—É–µ—Ç—Å—è", "–∑–∞—Ä–ø–ª–∞—Ç–∞",
]

# –ö–æ–º–ø–∏–ª–∏—Ä—É–µ–º –≤ –æ–¥–∏–Ω –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
_blacklist_pattern = re.compile(
    r"\b(" + "|".join(re.escape(w) for w in BLACKLIST_WORDS) + r")",
    re.IGNORECASE,
)


# ‚îÄ‚îÄ‚îÄ Whitelist: –º–∞—Ä–∫–µ—Ä—ã –∏–≤–µ–Ω—Ç–æ–≤ ‚îÄ‚îÄ‚îÄ

WHITELIST_WORDS = [
    # –†—É—Å—Å–∫–∏–µ
    "–∏–≤–µ–Ω—Ç", "–º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ", "–≤–µ—á–µ—Ä–∏–Ω–∫–∞", "—Ç—É—Å–æ–≤–∫–∞", "—Ç—É—Å–æ–≤–∫", "–º–∏—Ç–∞–ø",
    "–Ω–µ—Ç–≤–æ—Ä–∫–∏–Ω–≥", "–≤—Å—Ç—Ä–µ—á–∞", "—Å—Ö–æ–¥–∫–∞", "–¥–≤–∏–∂", "–¥–≤–∏–∂—É—Ö",
    "—Å–ø–æ—Ä—Ç", "–π–æ–≥–∞", "—Å–µ—Ä—Ñ–∏–Ω–≥", "–≤–æ–ª–µ–π–±–æ–ª", "—Ñ—É—Ç–±–æ–ª", "–±–µ–≥",
    "–º–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å", "–≤–æ—Ä–∫—à–æ–ø", "–ª–µ–∫—Ü–∏—è", "—Å–µ–º–∏–Ω–∞—Ä",
    "–∫–æ–Ω—Ü–µ—Ä—Ç", "—Ñ–µ—Å—Ç–∏–≤–∞–ª—å", "–≤–µ—á–µ—Ä", "–æ—Ç–∫—Ä—ã—Ç–∏–µ",
    "–≤—Ö–æ–¥", "–±–∏–ª–µ—Ç", "—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è", "–≤—Ö–æ–¥ —Å–≤–æ–±–æ–¥–Ω—ã–π",
    "–ø—Ä–∏–≥–ª–∞—à–∞–µ–º", "–ø—Ä–∏—Ö–æ–¥–∏—Ç–µ", "–∂–¥—ë–º", "–∂–¥–µ–º", "–ø—Ä–∏—Å–æ–µ–¥–∏–Ω—è–π—Ç–µ—Å—å",
    "–¥–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å",
    # English
    "event", "party", "meetup", "networking", "gathering",
    "workshop", "masterclass", "lecture", "seminar",
    "concert", "festival", "opening", "dj", "live music",
    "ticket", "free entry", "registration", "rsvp",
    "join us", "welcome", "come join",
    "sunset", "beach party", "pool party", "rooftop",
]

_whitelist_pattern = re.compile(
    r"\b(" + "|".join(re.escape(w) for w in WHITELIST_WORDS) + r")",
    re.IGNORECASE,
)


# ‚îÄ‚îÄ‚îÄ –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–∞—Ç –∏ –≤—Ä–µ–º–µ–Ω–∏ ‚îÄ‚îÄ‚îÄ

DATE_TIME_PATTERNS = [
    r"\d{1,2}[./]\d{1,2}(?:[./]\d{2,4})?",           # 15.02, 15/02/2025
    r"\d{1,2}\s*(?:—è–Ω–≤–∞—Ä—è|—Ñ–µ–≤—Ä–∞–ª—è|–º–∞—Ä—Ç–∞|–∞–ø—Ä–µ–ª—è|–º–∞—è|–∏—é–Ω—è|–∏—é–ª—è|–∞–≤–≥—É—Å—Ç–∞|—Å–µ–Ω—Ç—è–±—Ä—è|–æ–∫—Ç—è–±—Ä—è|–Ω–æ—è–±—Ä—è|–¥–µ–∫–∞–±—Ä—è)",
    r"\b(?:january|february|march|april|may|june|july|august|september|october|november|december)\s+\d{1,2}",
    r"\b–≤\s+\d{1,2}[:.]\d{2}\b",                       # –≤ 19:00, –≤ 20.30
    r"\b(?:at|from)\s+\d{1,2}[:.]\d{2}\b",             # at 19:00, from 20:30
    r"\d{1,2}[:.]\d{2}\s*(?:-|‚Äì|‚Äî)\s*\d{1,2}[:.]\d{2}", # 19:00 - 23:00
    r"\b(?:—Å–µ–≥–æ–¥–Ω—è|–∑–∞–≤—Ç—Ä–∞|–ø–æ—Å–ª–µ–∑–∞–≤—Ç—Ä–∞)\b",              # —Å–µ–≥–æ–¥–Ω—è, –∑–∞–≤—Ç—Ä–∞
    r"\b(?:today|tomorrow)\b",
    r"\b(?:–≤\s+)?(?:–ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫|–≤—Ç–æ—Ä–Ω–∏–∫|—Å—Ä–µ–¥[—É—ã]|—á–µ—Ç–≤–µ—Ä–≥|–ø—è—Ç–Ω–∏—Ü[—É—ã]|—Å—É–±–±–æ—Ç[—É—ã]|–≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å[–µ—è])\b",
    r"\b(?:on\s+)?(?:monday|tuesday|wednesday|thursday|friday|saturday|sunday)\b",
]

_datetime_pattern = re.compile(
    "|".join(DATE_TIME_PATTERNS),
    re.IGNORECASE,
)


# ‚îÄ‚îÄ‚îÄ –ü–∞—Ç—Ç–µ—Ä–Ω—ã –º–µ—Å—Ç ‚îÄ‚îÄ‚îÄ

LOCATION_PATTERNS = [
    r"üìç",
    r"\b(?:beach\s*club|bar|caf√©|cafe|–∫–∞—Ñ–µ|–±–∞—Ä|—Ä–µ—Å—Ç–æ—Ä–∞–Ω|restaurant)\b",
    r"\b(?:coworking|–∫–æ–≤–æ—Ä–∫–∏–Ω–≥|hub|—Ö–∞–±|space|–ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ)\b",
    r"\b(?:–∫–ª—É–±|club|pool|–±–∞—Å—Å–µ–π–Ω|rooftop|–∫—Ä—ã—à–∞)\b",
    r"\b(?:–∞–¥—Ä–µ—Å|address|–º–µ—Å—Ç–æ|location|venue|–ø–ª–æ—â–∞–¥–∫–∞)\b",
    r"\b(?:google\s*maps|goo\.gl|maps\.app)\b",
]

_location_pattern = re.compile(
    "|".join(LOCATION_PATTERNS),
    re.IGNORECASE,
)


# ‚îÄ‚îÄ‚îÄ –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ ‚îÄ‚îÄ‚îÄ

MIN_TEXT_LENGTH = 80


# ‚îÄ‚îÄ‚îÄ –ü–æ—Ä–æ–≥ –¥–ª—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è ‚îÄ‚îÄ‚îÄ

SCORE_THRESHOLD = 2


def _strip_urls(text: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç URL –∏–∑ —Ç–µ–∫—Å—Ç–∞ (–¥–ª—è –ø–æ–¥—Å—á—ë—Ç–∞ –¥–ª–∏–Ω—ã)."""
    return re.sub(r"https?://\S+", "", text)


def check(text: str, has_media: bool = False) -> FilterResult:
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è —á–µ—Ä–µ–∑ –≤—Å–µ —Ñ–∏–ª—å—Ç—Ä—ã.

    Args:
        text: –¢–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è.
        has_media: –ï—Å—Ç—å –ª–∏ –ø—Ä–∏–∫—Ä–µ–ø–ª—ë–Ω–Ω–æ–µ —Ñ–æ—Ç–æ/–≤–∏–¥–µ–æ.

    Returns:
        FilterResult —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –ø—Ä–æ–≤–µ—Ä–∫–∏.
    """
    if not text:
        return FilterResult(passed=False, score=0, reason="empty")

    # 1. Blacklist ‚Äî –Ω–µ–º–µ–¥–ª–µ–Ω–Ω—ã–π drop
    bl_match = _blacklist_pattern.search(text)
    if bl_match:
        return FilterResult(passed=False, score=-1, reason=f"blacklist: ¬´{bl_match.group()}¬ª")

    # 2. –î–ª–∏–Ω–∞ (–±–µ–∑ URL)
    clean_text = _strip_urls(text)
    if len(clean_text.strip()) < MIN_TEXT_LENGTH:
        return FilterResult(passed=False, score=0, reason=f"too_short: {len(clean_text.strip())} chars")

    # 3-6. –°–∫–æ—Ä–∏–Ω–≥
    score = 0
    reasons = []

    # Whitelist —Å–ª–æ–≤–∞
    wl_matches = _whitelist_pattern.findall(text)
    if wl_matches:
        score += min(len(wl_matches), 3)  # –ú–∞–∫—Å +3 –∑–∞ whitelist
        reasons.append(f"whitelist({len(wl_matches)}): {', '.join(set(wl_matches[:3]))}")

    # –î–∞—Ç–∞/–≤—Ä–µ–º—è
    dt_matches = _datetime_pattern.findall(text)
    if dt_matches:
        score += 2
        reasons.append(f"datetime({len(dt_matches)})")

    # –ú–µ—Å—Ç–æ
    loc_matches = _location_pattern.findall(text)
    if loc_matches:
        score += 1
        reasons.append(f"location({len(loc_matches)})")

    # –ú–µ–¥–∏–∞
    if has_media:
        score += 1
        reasons.append("has_media")

    passed = score >= SCORE_THRESHOLD
    reason_str = "; ".join(reasons) if reasons else "no_signals"

    return FilterResult(
        passed=passed,
        score=score,
        reason=f"score={score}/{SCORE_THRESHOLD} [{reason_str}]",
    )


def check_batch(messages: list[dict]) -> dict:
    """
    –ü—Ä–æ–≥–æ–Ω –ø–∞—á–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π —á–µ—Ä–µ–∑ —Ñ–∏–ª—å—Ç—Ä —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π.

    Args:
        messages: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∫–ª—é—á–∞–º–∏ 'text' –∏ 'media_type'.

    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –∏ —Å–ø–∏—Å–∫–∞–º–∏ –ø—Ä–æ—à–µ–¥—à–∏—Ö/–æ—Ç—Å–µ—è–Ω–Ω—ã—Ö.
    """
    passed = []
    dropped = []

    for msg in messages:
        text = msg.get("text", "")
        has_media = bool(msg.get("media_type"))
        result = check(text, has_media)
        msg["_filter"] = {
            "passed": result.passed,
            "score": result.score,
            "reason": result.reason,
        }
        if result.passed:
            passed.append(msg)
        else:
            dropped.append(msg)

    return {
        "total": len(messages),
        "passed": len(passed),
        "dropped": len(dropped),
        "pass_rate": f"{len(passed)/len(messages)*100:.1f}%" if messages else "0%",
        "passed_messages": passed,
        "dropped_messages": dropped,
    }
